<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the  Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>Quynh nguyen</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
</head>
<body>


<!-- Navigation -->
    <nav class="navbar navbar-inverse style="margin-left: 100px;"">
      <div class="container">
		<ul class="nav navbar-nav">
              <li><a href="#">Home</a></li>
              <li><a href="#papers">Papers</a></li>
              <li><a href="#teaching">Teaching</a></li>
		</ul>
	  </div>
	</nav>
  <!-- Page Content -->
    <div class="container">
        <div class="row">
            <!-- Contact Info on the Sidebar -->
            <div class="col-md-3 col-xs-12">
                <div style="word-wrap: break-word; font-family: 'Oswald', sans-serif; font-size: 32px;"><b>Quynh Nguyen</b></div><br>
                <div> <p><br> </div>
                <div class="row"> <div class="col-md-10 col-xs-4"> <img class="img-responsive" src="face.jpeg" alt=""></div></div><br>
                <div> <p>Email: me at quynhnguyen.org<br> </div>
            </div>
            <!-- Entries Column -->
            <div class="col-md-8 col-xs-12">
                <div class="col" style="margin-top:3%; text-align:justify;">
					             <p>Hello!</p>
                       <p>I am a machine learning researcher. Since 2017, I have been working on some mathematical aspects of deep learning.</p>

                       <p>I received my PhD (Dr. rer. nat) from Department of Mathematics and Computer Science at Saarland University in 2019,
                         where I work with <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/maschinelles-lernen/team/prof-dr-matthias-hein/">Matthias Hein</a>.
                         Prior to that, I did my undergrad at Vietnam National University Hanoi, and my master at Saarland University through the support of <a href="https://www.imprs-cs.de">IMPRS-CS</a> in Saarbrucken where I obtained my MSc degree in 2015.
                         After my PhD, I went to <a href="https://www.mis.mpg.de">MPI-MIS</a> for a Postdoc, working in the group of <a href="http://www.math.ucla.edu/~montufar/">Guido Montufar</a>.
                         Beside that, I also spent some time working at TU Kaiserslauter (as a postdoc) and DFKI (German Center for Artificial Intelligence) as a senior researcher.
                       </p>

                       <p>I was one of the research fellows at Simons-Berkeley Institute in 2019, where I participated in the program <a href="https://simons.berkeley.edu/programs/dl2019">Foundation of deep learning</a>.
                         In the same year, I also visited a workshop on deep learning theory at IST Austria.
                       </p>
                </div>
                <div class="col">
                    <h2 id="papers">Papers</h2>
                    <h3>Provable guarantees for training neural networks</h3>

                    <p><b>
                    <a href="https://arxiv.org/abs/2101.09612">On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths</a></b><br>
                    <b>Quynh Nguyen</b>. ICML 2021
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/2002.07867">Global Convergence of Deep Networks with One Wide Layer Followed by Pyramidal Topology</a></b><br>
                    <b>Quynh Nguyen</b> and Marco Mondelli. ICML 2020
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1610.09300">Globally Optimal Training of Generalized Polynomial Neural Networks with Nonlinear Spectral Methods</a></b><br>
                    Antoine Gautier, <b>Quynh Nguyen</b> and Matthias Hein. NIPS 2016
                    </p>
                    <p></p>



                    <h3>Loss surface, optimization landscape, sublevel sets</h3>
                    <p><b>
                    <a href="https://arxiv.org/abs/2101.08576">A Note on Connectivity of Sublevel Sets in Deep Learning</a></b><br>
                    <b>Quynh Nguyen</b>. Technical note, 2021
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/2102.09671">When Are Solutions Connected in Deep Networks?</a></b><br>
                    <b>Quynh Nguyen</b>, Pierre Brechet and Marco Mondelli. NeurIPS 2021
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1901.07417">On Connected Sublevel Sets in Deep Learning</a></b><br>
                    <b>Quynh Nguyen</b>. ICML 2019
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1809.10749">On the Loss Landscape of a Class of Deep Neural Networks with No Bad Local Valleys</a></b><br>
                    <b>Quynh Nguyen</b>, Mahesh Chandra Mukkamala and Matthias Hein. ICLR 2019
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1803.00094">Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions</a></b><br>
                    <b>Quynh Nguyen</b>, Mahesh Mukkamala and Matthias Hein. ICML 2018
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1710.10928">Optimization Landscape and Expressivity of Deep CNNs</a></b><br>
                    <b>Quynh Nguyen</b> and Matthias Hein. ICML 2018
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1704.08045">The Loss Surface of Deep and Wide Neural Networks</a></b><br>
                    <b>Quynh Nguyen</b> and Matthias Hein. ICML 2017
                    </p>
                    <p></p>



                    <h3>Neural tangent kernel</h3>
                    <p><b>
                    <a href="https://arxiv.org/abs/2012.11654">Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks</a></b><br>
                    <b>Quynh Nguyen</b>, Marco Mondelli and Guido Montufar. ICML 2021
                    </p>
                    <p></p>

                    <h3>Initialization of deep networks</h3>
                    <p><b>
                    <a href="https://arxiv.org/abs/2101.12017">A Fully Rigorous Proof of the Derivation of Xavier and He's Initialization for Deep ReLU Networks</a></b><br>
                    <b>Quynh Nguyen</b>. Technical note, 2021
                    </p>
                    <p></p>

                    <h3>Nonconvex optimization</h3>
                    <p><b>
                    <a href="https://www.ml.uni-saarland.de/Publications/NgGauHei-OPT2016.pdf">Nonlinear Spectral Methods for Nonconvex Optimization with Global Optimality</a></b><br>
                    <b>Quynh Nguyen</b>, Antoine Gautier and Matthias hein. NIPS Workshop on Optimization, 2016
                    </p>
                    <p></p>

                    <h3>Computer vision</h3>
                    <p><b>
                    <a href="https://arxiv.org/abs/1511.02667">An Efficient Multilinear Optimization Framework for Hypergraph Matching</a></b><br>
                    <b>Quynh nguyen</b>, Francesco Tudisco, Antoine Gautier and Matthias Hein. T-PAMI 2017
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://arxiv.org/abs/1504.07907">A Flexible Tensor Block Coordinate Ascent Scheme for Hypergraph Matching</a></b><br>
                    <b>Quynh Nguyen</b>, Antoine Gautier and Matthias Hein. CVPR 2015
                    </p>
                    <p></p>

                    <p><b>
                    <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Xian_Latent_Embeddings_for_CVPR_2016_paper.pdf">Latent Embeddings for Zero-shot Classification</a></b><br>
                    Yongqin Xian, Zeynep Akata, Gaurav Sharma, <b>Quynh Nguyen</b>, Matthias Hein and Bernt Schiele. CVPR 2016
                    </p>
                    <p></p>


                </div>
                <div class="col">
                    <h2 id="teaching">Teaching</h2>
                        <p><b>Convex Optimization</b> </p>
                        <p><b>Advanced Topics in Machine Learning</b> (Seminar)</p>
                </div>
            </div>
    </div>
    </div>

</body>

</html>
